{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6ac0157-ebfe-45e5-a22f-5d5172b0e135",
   "metadata": {},
   "source": [
    "# Temperature and TopK\n",
    "\n",
    "**Descrição:**\n",
    "Notebook focado em estratégias de *decoding* para geração de texto em modelos GPT-like, mostrando como **temperature scaling** e **top-k sampling** alteram a aleatoriedade (diversidade) e a coerência do texto gerado. \n",
    "\n",
    "**Objetivo:**\n",
    "Demonstrar, de forma prática, como ajustar os hiperparâmetros **temperature** e **top_k** para controlar o comportamento do modelo na etapa de inferência — indo de uma geração determinística (greedy) para uma geração probabilística com maior variedade.\n",
    "\n",
    "**Funcionamento:**\n",
    "1. Define a configuração do modelo (mesma base do notebook de arquitetura, com *context_length* reduzido) e carrega o modelo previamente treinado.\n",
    "2. Mostra o comportamento determinístico quando o próximo token é escolhido de forma “gulosa” (sempre o mais provável).\n",
    "3. Introduz uma função de geração que aplica:\n",
    "   - **Top-k sampling**: restringe a amostragem aos *k* tokens mais prováveis;\n",
    "   - **Temperature scaling**: “achata” ou “afunila” a distribuição de probabilidade antes de amostrar. \n",
    "4. Executa experimentos comparando diferentes temperaturas (ex.: 0.1, 1, 5) e observa como a distribuição muda (mais conservadora vs. mais criativa), repetindo a geração do próximo token para evidenciar a variabilidade.\n",
    "\n",
    "\n",
    "![Bloco transformer](../../imagens/cap05/02_temperature_and_topk.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc1c1613-3feb-4c06-bd47-195e6dbff99d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections.abc import Sequence\n",
    "from dataclasses import dataclass\n",
    "from typing import Any\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tiktoken\n",
    "import torch\n",
    "\n",
    "from build_llm.gpt import GPTModel\n",
    "from build_llm.util import generate_text_simple, text_to_token_ids, token_ids_to_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5880fc0-3ca5-44b5-b477-286d8685de06",
   "metadata": {},
   "source": [
    "## Configuração do modelo\n",
    "\n",
    "As mesmas utilizadas no notebook [01 - LLM architecture](./01%20-%20LLM%20architecture.ipynb)\n",
    "**exceto** pela janela de contexto (context_length) que foi reduziada para 256 (anteriormente era 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1996428d-075b-4a2b-b87f-dc91a56c6c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M: dict[str, Any] = {\n",
    "    \"vocab_size\": 50257,  # Tamanho do vocabulário\n",
    "    \"context_length\": 256,  # Comprimento do contexto\n",
    "    \"emb_dim\": 768,  # Dimensão do embedding\n",
    "    \"n_heads\": 12,  # Número de cabeças de atenção\n",
    "    \"n_layers\": 12,  # Número de camadas\n",
    "    \"drop_rate\": 0.1,  # Taxa de dropout\n",
    "    \"qkv_bias\": False,  # Viés em Query-Key-Value (QKV)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84f9eecf-b31a-4cda-9fac-678519adc27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device() -> torch.device:\n",
    "    \"\"\"\n",
    "    Retorna o device apropriado (CUDA se disponível, caso contrário CPU).\n",
    "    \"\"\"\n",
    "    return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b039bb56-6bdb-469b-948d-80b25f5dce41",
   "metadata": {},
   "source": [
    "## Carrega o modelo \n",
    "Treinado no notebook [01 - GPT Training](./01%20-%20GPT%20Training.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a20f3f96-d6b3-4c8c-90d2-6b1276794a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inicializa o tokenizer (encoding compatível com GPT-2)\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "device = get_device()\n",
    "print(\"Device:\", device)\n",
    "\n",
    "model.load_state_dict(\n",
    "    torch.load(\"../../models/my_gpt.pth\", map_location=device, weights_only=True)\n",
    ")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88147c5-3a69-4d83-96d1-a6d4a2f50977",
   "metadata": {},
   "source": [
    "### Aqui o modelo sempre gera o mesmo resultado (mesmo que executado múltiplas vezes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1bcd75f-0763-4034-9806-7429bd7fd878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto de saída:\n",
      "Quando voltámos, á noite, viemos por allição,\n",
      "olhos de tão\n"
     ]
    }
   ],
   "source": [
    "# Gera texto a partir de um prompt inicial\n",
    "prompt = \"Quando voltámos, á noite, viemos por alli\"\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(prompt, tokenizer).to(device),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    ")\n",
    "\n",
    "# Decodifica e imprime o resultado\n",
    "output_text = token_ids_to_text(token_ids, tokenizer)\n",
    "print(f\"Texto de saída:\\n{output_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5d826f3-d944-4b45-b1cf-cbde99c1f0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto de saída:\n",
      "Quando voltámos, á noite, viemos por allição,\n",
      "olhos de tão\n"
     ]
    }
   ],
   "source": [
    "# Gera texto a partir de um prompt inicial\n",
    "prompt = \"Quando voltámos, á noite, viemos por alli\"\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(prompt, tokenizer).to(device),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    ")\n",
    "\n",
    "# Decodifica e imprime o resultado\n",
    "output_text = token_ids_to_text(token_ids, tokenizer)\n",
    "print(f\"Texto de saída:\\n{output_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4a972c-5858-4d10-8d4d-08a965b89d9b",
   "metadata": {},
   "source": [
    "# Função final para gerar a partir do TopK e Temperatura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7956f9b6-f404-4b20-9f6a-f1020da500ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(\n",
    "    model,\n",
    "    idx,\n",
    "    max_new_tokens,\n",
    "    context_size,\n",
    "    temperature: float = 0.0,\n",
    "    top_k=None,\n",
    "    eos_id=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Gera novos tokens a partir de um modelo autoregressivo.\n",
    "\n",
    "    Parâmetros:\n",
    "    ----------\n",
    "    model\n",
    "        Modelo que recebe `idx_cond` e retorna logits no formato (batch, seq_len, vocab).\n",
    "    idx\n",
    "        Tensor com os índices atuais (batch_size, seq_len).\n",
    "    max_new_tokens\n",
    "        Número máximo de novos tokens a serem gerados.\n",
    "    context_size\n",
    "        Tamanho do contexto (janela) usado a cada passo.\n",
    "    temperature : float, default = 0.0\n",
    "        Temperatura para amostragem. Se 0.0, usa greedy (argmax).\n",
    "    top_k : int | None, default = None\n",
    "        Se definido, aplica filtragem top-k antes de amostrar.\n",
    "    eos_id : int | None, default = None\n",
    "        Id do token de fim de sequência. Se encontrado, encerra a geração.\n",
    "\n",
    "    Retorno:\n",
    "    -------\n",
    "    Tensor\n",
    "        Sequência final com os tokens gerados (batch_size, seq_len + tokens_gerados).\n",
    "    \"\"\"\n",
    "    # O laço é o mesmo de antes: obtém os logits e considera apenas o último passo de tempo\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # Novo: filtra os logits usando amostragem top-k\n",
    "        if top_k is not None:\n",
    "            # Mantém apenas os top_k maiores valores\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(\n",
    "                logits < min_val,\n",
    "                torch.tensor(float(\"-inf\"), device=logits.device),\n",
    "                logits,\n",
    "            )\n",
    "\n",
    "        # Novo: aplica escalonamento por temperatura\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "\n",
    "            # Novo (não está no livro): dica de estabilidade numérica para obter resultados equivalentes no device MPS\n",
    "            # Subtrai o máximo por linha antes do softmax\n",
    "            logits = logits - logits.max(dim=-1, keepdim=True).values\n",
    "\n",
    "            # Aplica softmax para obter probabilidades\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, vocab_size)\n",
    "\n",
    "            # Amostra da distribuição\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "        else:\n",
    "            # Caso contrário, como antes: pega o índice com o maior valor de logits (greedy)\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "        # Para a geração cedo se o token de fim de sequência for encontrado e eos_id tiver sido especificado\n",
    "        if eos_id is not None and (idx_next == eos_id).all():\n",
    "            break\n",
    "\n",
    "        # Como antes: concatena o índice amostrado à sequência em execução\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens + 1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06f65da-28f0-4d94-8bc9-ebfcc02e4d30",
   "metadata": {},
   "source": [
    "### O texto abaixo já é distinto dos anteriores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25ea7858-b6ed-4d36-9f01-0411abf8cfd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Quando voltámos, á noite, viemos por alli um modo,...\n",
      "\n",
      "Este,\n"
     ]
    }
   ],
   "source": [
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Quando voltámos, á noite, viemos por alli\", tokenizer).to(\n",
    "        device\n",
    "    ),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=10,\n",
    "    temperature=1.5,\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107841e9-9c92-4614-84a2-e33834cef98f",
   "metadata": {},
   "source": [
    "## Verificando a influência do TOP-K e da temperatura na geração do próximo token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "769aae94-fc2b-4a3e-b2b1-7bed2ed27bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class TopKDistribution:\n",
    "    \"\"\"\n",
    "    Estrutura para armazenar a distribuição top-k do próximo token.\n",
    "\n",
    "    Atributos:\n",
    "    ---------\n",
    "    token_ids : torch.Tensor\n",
    "        Tensor (top_k,) com os ids dos tokens no vocabulário.\n",
    "    probs : torch.Tensor\n",
    "        Tensor (top_k,) com as probabilidades correspondentes.\n",
    "    tokens : List[str]\n",
    "        Lista (top_k,) com a representação textual de cada token.\n",
    "    temperature : float\n",
    "        Temperatura usada para escalonar os logits.\n",
    "    top_k : int\n",
    "        Valor de k usado na filtragem top-k.\n",
    "    \"\"\"\n",
    "\n",
    "    token_ids: torch.Tensor\n",
    "    probs: torch.Tensor\n",
    "    tokens: list[str]\n",
    "    temperature: float\n",
    "    top_k: int\n",
    "\n",
    "\n",
    "def _apply_top_k_filter(logits: torch.Tensor, top_k: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Aplica filtragem top-k em logits 2D (batch, vocab).\n",
    "\n",
    "    Mantém apenas os top_k maiores logits por linha e zera (via -inf) o resto.\n",
    "    \"\"\"\n",
    "    if top_k <= 0:\n",
    "        raise ValueError(\"top_k deve ser um inteiro positivo (> 0).\")\n",
    "\n",
    "    top_logits, _ = torch.topk(logits, k=top_k, dim=-1)\n",
    "    min_val = top_logits[:, -1].unsqueeze(-1)  # (batch, 1)\n",
    "    filtered = torch.where(\n",
    "        logits < min_val,\n",
    "        torch.tensor(float(\"-inf\"), device=logits.device, dtype=logits.dtype),\n",
    "        logits,\n",
    "    )\n",
    "    return filtered\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def next_token_topk_distributions(\n",
    "    model,\n",
    "    idx: torch.Tensor,\n",
    "    context_size: int,\n",
    "    temperatures: Sequence[float] = (1.0, 0.1, 5.0),\n",
    "    top_k: int = 25,\n",
    "    tokenizer=None,\n",
    ") -> dict[float, TopKDistribution]:\n",
    "    \"\"\"\n",
    "    Calcula a distribuição top-k do *próximo token* para várias temperaturas.\n",
    "\n",
    "    Parâmetros:\n",
    "    ----------\n",
    "    model\n",
    "        Modelo autoregressivo: recebe idx_cond e retorna logits (batch, seq, vocab).\n",
    "    idx : torch.Tensor\n",
    "        Tensor (batch, seq_len) com os ids dos tokens de contexto.\n",
    "        Observação: para o gráfico, o batch deve ser 1.\n",
    "    context_size : int\n",
    "        Tamanho máximo da janela de contexto usada (recorta idx no final).\n",
    "    temperatures : Sequence[float]\n",
    "        Lista/tupla de temperaturas a comparar (ex.: [1, 0.1, 5]).\n",
    "        Recomendação: evitar 0 aqui; 0 é \"greedy\", não uma distribuição.\n",
    "    top_k : int\n",
    "        Top-k para filtrar logits antes do softmax.\n",
    "    tokenizer : opcional\n",
    "        Tokenizer com decode(list[int]) ou decode(int)/id->string.\n",
    "        Se None, o campo `tokens` vira strings com os ids.\n",
    "\n",
    "    Retorno:\n",
    "    -------\n",
    "    Dict[float, TopKDistribution]\n",
    "        Um dicionário {temperatura: distribuição_topk}.\n",
    "    \"\"\"\n",
    "    if idx.dim() != 2:\n",
    "        raise ValueError(\"idx deve ter shape (batch, seq_len).\")\n",
    "    if idx.size(0) != 1:\n",
    "        raise ValueError(\"Para plotar de forma legível, use batch_size=1.\")\n",
    "    if top_k is None:\n",
    "        raise ValueError(\"top_k precisa ser definido para esta função.\")\n",
    "\n",
    "    # 1) logits do último passo\n",
    "    idx_cond = idx[:, -context_size:]\n",
    "    logits = model(idx_cond)  # (1, seq, vocab)\n",
    "    logits = logits[:, -1, :]  # (1, vocab)\n",
    "\n",
    "    # 2) top-k filter (uma vez) – depois cada temperatura só reescala\n",
    "    logits_topk = _apply_top_k_filter(logits, top_k=top_k)\n",
    "\n",
    "    results: dict[float, TopKDistribution] = {}\n",
    "\n",
    "    for t in temperatures:\n",
    "        if t <= 0:\n",
    "            raise ValueError(f\"Temperatura deve ser > 0. Recebido: {t}\")\n",
    "\n",
    "        # 3) temperature scaling\n",
    "        scaled = logits_topk / float(t)\n",
    "\n",
    "        # dica de estabilidade numérica\n",
    "        scaled = scaled - scaled.max(dim=-1, keepdim=True).values\n",
    "\n",
    "        # 4) probs\n",
    "        probs = torch.softmax(scaled, dim=-1)  # (1, vocab)\n",
    "\n",
    "        # 5) extrai top_k final (já deve coincidir com o top_k filtrado, mas garantimos)\n",
    "        p_top, ids_top = torch.topk(probs, k=top_k, dim=-1)\n",
    "        p_top = p_top.squeeze(0).detach().cpu()\n",
    "        ids_top = ids_top.squeeze(0).detach().cpu()\n",
    "\n",
    "        if tokenizer is None:\n",
    "            tokens = [str(int(i)) for i in ids_top.tolist()]\n",
    "        else:\n",
    "            # tenta caminhos comuns de decode\n",
    "            tokens = []\n",
    "            for i in ids_top.tolist():\n",
    "                try:\n",
    "                    tokens.append(tokenizer.decode([int(i)]))\n",
    "                except Exception:\n",
    "                    try:\n",
    "                        tokens.append(tokenizer.decode(int(i)))\n",
    "                    except Exception:\n",
    "                        tokens.append(str(int(i)))\n",
    "\n",
    "        results[float(t)] = TopKDistribution(\n",
    "            token_ids=ids_top,\n",
    "            probs=p_top,\n",
    "            tokens=tokens,\n",
    "            temperature=float(t),\n",
    "            top_k=int(top_k),\n",
    "        )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cb80e20-7b86-4d75-b9cf-650290d6afa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_topk_temperature_comparison(\n",
    "    dists: dict[float, TopKDistribution],\n",
    "    title: str = \"Distribuição top-k do próximo token por temperatura\",\n",
    "    rotate_xticks: int = 45,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Plota barras agrupadas comparando as probabilidades top-k entre temperaturas.\n",
    "\n",
    "    Observação importante:\n",
    "    - Cada temperatura pode ter um top-k (lista de tokens) diferente.\n",
    "      Para ficar “tipo o anexo”, usamos a união dos tokens e colocamos 0 onde não aparecer.\n",
    "    \"\"\"\n",
    "    if not dists:\n",
    "        raise ValueError(\"dists está vazio.\")\n",
    "\n",
    "    temps = sorted(dists.keys())\n",
    "    # União de tokens (na ordem: usa a ordem da menor temperatura como base e adiciona o resto)\n",
    "    base_tokens = dists[temps[0]].tokens\n",
    "    token_set = list(base_tokens)\n",
    "    seen = set(base_tokens)\n",
    "\n",
    "    for t in temps[1:]:\n",
    "        for tok in dists[t].tokens:\n",
    "            if tok not in seen:\n",
    "                token_set.append(tok)\n",
    "                seen.add(tok)\n",
    "\n",
    "    # matriz de probs: (n_temps, n_tokens_union)\n",
    "    prob_mat = []\n",
    "    for t in temps:\n",
    "        tok2p = {\n",
    "            tok: float(p)\n",
    "            for tok, p in zip(dists[t].tokens, dists[t].probs.tolist(), strict=False)\n",
    "        }\n",
    "        prob_mat.append([tok2p.get(tok, 0.0) for tok in token_set])\n",
    "\n",
    "    n_temps = len(temps)\n",
    "    n_tokens = len(token_set)\n",
    "\n",
    "    x = torch.arange(n_tokens).numpy()\n",
    "    width = 0.8 / max(n_temps, 1)\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    for i, t in enumerate(temps):\n",
    "        offset = (i - (n_temps - 1) / 2) * width\n",
    "        plt.bar(x + offset, prob_mat[i], width=width, label=f\"Temperature = {t}\")\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.ylabel(\"Probability\")\n",
    "    plt.xticks(x, token_set, rotation=rotate_xticks, ha=\"right\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4780fb9d-5917-4f16-8e82-d52bbe42e5e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = text_to_token_ids(\"Quando voltámos, á noite, viemos por alli\", tokenizer).to(\n",
    "    device\n",
    ")\n",
    "dists = next_token_topk_distributions(\n",
    "    model=model,\n",
    "    idx=idx,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    temperatures=[1, 0.1, 5],  # Original, higher confidence, and lower confidence\n",
    "    top_k=10,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "plot_topk_temperature_comparison(dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "014b91fa-349f-4cc5-b934-6b578ad1c84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Temperature=1.0\n",
      "'ç': 0.6004\n",
      "' um': 0.0865\n",
      "' os': 0.0749\n",
      "' h': 0.0332\n",
      "' a': 0.0273\n",
      "' de': 0.0272\n",
      "'ça': 0.0191\n",
      "' em': 0.0149\n",
      "' que': 0.0125\n",
      "' aff': 0.0122\n",
      "\n",
      "Temperature=0.1\n",
      "'ç': 1.0000\n",
      "' um': 0.0000\n",
      "' os': 0.0000\n",
      "' h': 0.0000\n",
      "' a': 0.0000\n",
      "' de': 0.0000\n",
      "'ça': 0.0000\n",
      "' em': 0.0000\n",
      "' que': 0.0000\n",
      "' aff': 0.0000\n",
      "\n",
      "Temperature=5.0\n",
      "'ç': 0.0980\n",
      "' um': 0.0666\n",
      "' os': 0.0647\n",
      "' h': 0.0550\n",
      "' a': 0.0528\n",
      "' de': 0.0528\n",
      "'ça': 0.0492\n",
      "' em': 0.0468\n",
      "' que': 0.0452\n",
      "' aff': 0.0450\n"
     ]
    }
   ],
   "source": [
    "for t, dist in dists.items():\n",
    "    print(f\"\\nTemperature={t}\")\n",
    "    for tok, p in list(zip(dist.tokens, dist.probs.tolist(), strict=False))[:10]:\n",
    "        print(f\"{tok!r}: {p:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631b200a-3b71-48d7-9c1e-cd4bfa8f35cd",
   "metadata": {},
   "source": [
    "### Gerando o próximo token 5 vezes com a temperatura em 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "058822e7-61ff-4206-a6a9-e919d4ffcce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Output text:\n",
      " Quando voltámos, á noite, viemos por alliç\n",
      "1\n",
      "Output text:\n",
      " Quando voltámos, á noite, viemos por alliç\n",
      "2\n",
      "Output text:\n",
      " Quando voltámos, á noite, viemos por alliç\n",
      "3\n",
      "Output text:\n",
      " Quando voltámos, á noite, viemos por alliç\n",
      "4\n",
      "Output text:\n",
      " Quando voltámos, á noite, viemos por alliç\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(i)\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(\n",
    "            \"Quando voltámos, á noite, viemos por alli\", tokenizer\n",
    "        ).to(device),\n",
    "        max_new_tokens=1,\n",
    "        context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "        top_k=10,\n",
    "        temperature=0.1,\n",
    "    )\n",
    "\n",
    "    print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a06526-40ce-46df-8465-4926d16a5264",
   "metadata": {},
   "source": [
    "### Gerando o próximo token 5 vezes com a temperatura em 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4bb2b0c2-44ea-40e2-b2eb-6c5f4a6ed76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Output text:\n",
      " Quando voltámos, á noite, viemos por alli de\n",
      "1\n",
      "Output text:\n",
      " Quando voltámos, á noite, viemos por alliç\n",
      "2\n",
      "Output text:\n",
      " Quando voltámos, á noite, viemos por alli um\n",
      "3\n",
      "Output text:\n",
      " Quando voltámos, á noite, viemos por alliç\n",
      "4\n",
      "Output text:\n",
      " Quando voltámos, á noite, viemos por alliç\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(i)\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(\n",
    "            \"Quando voltámos, á noite, viemos por alli\", tokenizer\n",
    "        ).to(device),\n",
    "        max_new_tokens=1,\n",
    "        context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "        top_k=10,\n",
    "        temperature=1,\n",
    "    )\n",
    "\n",
    "    print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a68e5f9-bcc2-4464-8757-86e30080452b",
   "metadata": {},
   "source": [
    "### Gerando o próximo token 5 vezes com a temperatura em 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65bd4a87-7b5c-46ef-a3a6-8afd53fc89bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Output text:\n",
      " Quando voltámos, á noite, viemos por alli um\n",
      "1\n",
      "Output text:\n",
      " Quando voltámos, á noite, viemos por alli h\n",
      "2\n",
      "Output text:\n",
      " Quando voltámos, á noite, viemos por alliça\n",
      "3\n",
      "Output text:\n",
      " Quando voltámos, á noite, viemos por alli um\n",
      "4\n",
      "Output text:\n",
      " Quando voltámos, á noite, viemos por alliç\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(i)\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(\n",
    "            \"Quando voltámos, á noite, viemos por alli\", tokenizer\n",
    "        ).to(device),\n",
    "        max_new_tokens=1,\n",
    "        context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "        top_k=10,\n",
    "        temperature=5,\n",
    "    )\n",
    "\n",
    "    print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

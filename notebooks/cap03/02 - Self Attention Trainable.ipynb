{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9e38794-ca28-46c9-8ca9-b6ed788092d2",
   "metadata": {},
   "source": [
    "# Self-attention with trainable weights\n",
    "**Descrição**  \n",
    "Nesta etapa, vamos implementar **self-attention com pesos treináveis**, substituindo a versão “fixa” (sem parâmetros) por projeções lineares aprendíveis que geram **queries (Q)**, **keys (K)** e **values (V)**. Isso permite que o modelo aprenda, a partir dos dados, **quais relações entre tokens são mais relevantes** para compor representações contextualizadas. :contentReference[oaicite:0]{index=0}\n",
    "\n",
    "**Objetivo**  \n",
    "- Construir uma camada de self-attention **parametrizada** (com matrizes de pesos treináveis).  \n",
    "- Entender o fluxo completo: **X → (Q, K, V) → scores → pesos de atenção → contexto**.  \n",
    "- Preparar o terreno para evoluir para **causal attention** e, depois, **multi-head attention**.\n",
    "\n",
    "**Funcionamento**  \n",
    "1. **Entrada (X)**: embeddings dos tokens (matriz com formato `[seq_len, d_in]`).  \n",
    "2. **Projeções treináveis**: aplicamos camadas lineares para obter:\n",
    "   - `Q = X · W_q`, `K = X · W_k`, `V = X · W_v`  \n",
    "3. **Similaridade (scores)**: calculamos a afinidade entre tokens via produto escalar:\n",
    "   - `scores = Q · Kᵀ` (opcionalmente escalado em versões posteriores)  \n",
    "4. **Normalização (softmax)**: transformamos scores em **pesos de atenção** (distribuição por token).  \n",
    "5. **Agregação**: combinamos informações ponderadas:\n",
    "   - `context = attention_weights · V`  \n",
    "6. **Saída**: representações contextualizadas, onde cada token incorpora informação de outros tokens conforme aprendido pelos pesos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b33383d3-ffec-4848-8c90-e37feb858788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1b11a109cb0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Para reprodutibilidade\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12fd88d-4a81-4014-98aa-76dc42acc479",
   "metadata": {},
   "source": [
    "## Frase de exemplo e vocabulário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfc587e2-948b-48ef-8a03-9946a3804359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulário:\n",
      "O -> 0\n",
      "gato -> 1\n",
      "sobe -> 2\n",
      "no -> 3\n",
      "tapete -> 4\n"
     ]
    }
   ],
   "source": [
    "# Frase de exemplo\n",
    "sentence = \"O gato sobe no tapete\".split()\n",
    "\n",
    "# Vocabulário\n",
    "vocab = {word: idx for idx, word in enumerate(sentence)}\n",
    "inv_vocab = {idx: word for word, idx in vocab.items()}\n",
    "\n",
    "print(\"Vocabulário:\")\n",
    "for k, v in vocab.items():\n",
    "    print(f\"{k} -> {v}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cd3a8a-9a75-4e32-ad3c-a4079c4706bc",
   "metadata": {},
   "source": [
    "## Conversão para índices (tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7a54fcf-f476-4c93-97cf-d2ad11652571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens:\n",
      "O -> 0\n",
      "gato -> 1\n",
      "sobe -> 2\n",
      "no -> 3\n",
      "tapete -> 4\n"
     ]
    }
   ],
   "source": [
    "# Convertendo palavras para índices\n",
    "token_ids = torch.tensor([vocab[word] for word in sentence])\n",
    "\n",
    "print(\"Tokens:\")\n",
    "for word, idx in zip(sentence, token_ids):\n",
    "    print(f\"{word} -> {idx.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8947fb-62ea-46c4-9aa2-1bccc5b4d948",
   "metadata": {},
   "source": [
    "## Camada de Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84582284-5747-4e2e-aca8-4dd50664b67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape dos embeddings: torch.Size([5, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3367,  0.1288,  0.2345],\n",
       "        [ 0.2303, -1.1229, -0.1863],\n",
       "        [ 2.2082, -0.6380,  0.4617],\n",
       "        [ 0.2674,  0.5349,  0.8094],\n",
       "        [ 1.1103, -1.6898, -0.9890]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dim = 3  # dimensão pequena para fins didáticos\n",
    "\n",
    "embedding = nn.Embedding(\n",
    "    num_embeddings=vocab_size,\n",
    "    embedding_dim=embedding_dim\n",
    ")\n",
    "\n",
    "# Aplicando embedding\n",
    "X = embedding(token_ids)\n",
    "\n",
    "print(\"Shape dos embeddings:\", X.shape)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d261b089-4d63-4c66-b959-573dbf9b608e",
   "metadata": {},
   "source": [
    "## Definição da camada de Self-Attention (pesos treináveis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb86f4d2-ecb6-4e4a-8a3b-7ae3ab85064e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, d_in: int, d_attn: int):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.W_q = nn.Linear(d_in, d_attn, bias=False)\n",
    "        self.W_k = nn.Linear(d_in, d_attn, bias=False)\n",
    "        self.W_v = nn.Linear(d_in, d_attn, bias=False)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        \"\"\"\n",
    "        x: Tensor de shape [seq_len, d_in]\n",
    "        \"\"\"\n",
    "        Q = self.W_q(x)\n",
    "        K = self.W_k(x)\n",
    "        V = self.W_v(x)\n",
    "\n",
    "        # Produto escalar entre queries e keys\n",
    "        scores = Q @ K.T\n",
    "\n",
    "        # Softmax para obter pesos de atenção\n",
    "        attn_weights = F.softmax(scores, dim=-1)\n",
    "\n",
    "        # Combinação ponderada dos values\n",
    "        context = attn_weights @ V\n",
    "\n",
    "        return context, attn_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab06d90b-5833-455d-9b31-0148608b5f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape do contexto: torch.Size([5, 3])\n",
      "Shape dos pesos de atenção: torch.Size([5, 5])\n"
     ]
    }
   ],
   "source": [
    "d_attn = 3\n",
    "\n",
    "self_attention = SelfAttention(\n",
    "    d_in=embedding_dim,\n",
    "    d_attn=d_attn\n",
    ")\n",
    "\n",
    "context, attn_weights = self_attention(X)\n",
    "\n",
    "print(\"Shape do contexto:\", context.shape)\n",
    "print(\"Shape dos pesos de atenção:\", attn_weights.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529e4476-75d2-4f87-983d-4d9ec95eb3f6",
   "metadata": {},
   "source": [
    "## Visualizando os pesos de atenção (parte mais didática)\n",
    "\n",
    "Aqui mostramos quem presta atenção em quem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6def1531-2cb7-4716-8b32-db9b4b69feef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pesos de atenção:\n",
      "\n",
      "Palavra: 'O'\n",
      "  → atenção em 'O': 0.1942\n",
      "  → atenção em 'gato': 0.1878\n",
      "  → atenção em 'sobe': 0.2300\n",
      "  → atenção em 'no': 0.2064\n",
      "  → atenção em 'tapete': 0.1816\n",
      "\n",
      "Palavra: 'gato'\n",
      "  → atenção em 'O': 0.2115\n",
      "  → atenção em 'gato': 0.1965\n",
      "  → atenção em 'sobe': 0.1864\n",
      "  → atenção em 'no': 0.2089\n",
      "  → atenção em 'tapete': 0.1967\n",
      "\n",
      "Palavra: 'sobe'\n",
      "  → atenção em 'O': 0.1889\n",
      "  → atenção em 'gato': 0.1312\n",
      "  → atenção em 'sobe': 0.3133\n",
      "  → atenção em 'no': 0.2741\n",
      "  → atenção em 'tapete': 0.0926\n",
      "\n",
      "Palavra: 'no'\n",
      "  → atenção em 'O': 0.1720\n",
      "  → atenção em 'gato': 0.1814\n",
      "  → atenção em 'sobe': 0.2707\n",
      "  → atenção em 'no': 0.1786\n",
      "  → atenção em 'tapete': 0.1973\n",
      "\n",
      "Palavra: 'tapete'\n",
      "  → atenção em 'O': 0.2458\n",
      "  → atenção em 'gato': 0.1744\n",
      "  → atenção em 'sobe': 0.1636\n",
      "  → atenção em 'no': 0.2930\n",
      "  → atenção em 'tapete': 0.1232\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Pesos de atenção:\\n\")\n",
    "\n",
    "for i, word in enumerate(sentence):\n",
    "    print(f\"Palavra: '{word}'\")\n",
    "    for j, weight in enumerate(attn_weights[i]):\n",
    "        print(f\"  → atenção em '{sentence[j]}': {weight.item():.4f}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f576df-9cb9-4d6b-a277-c214dda9ed44",
   "metadata": {},
   "source": [
    "### O que aprendemos aqui?\n",
    "\n",
    "- Cada palavra gera sua própria **Query, Key e Value**\n",
    "- A atenção é calculada comparando **Query × Key**\n",
    "- O softmax transforma similaridade em **distribuição de atenção**\n",
    "- O contexto final é uma **soma ponderada dos Values**\n",
    "- Os pesos `W_q`, `W_k`, `W_v` são **treináveis**, permitindo ao modelo aprender relações semânticas\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

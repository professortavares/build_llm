{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "694fe7b3-3092-4c1e-a365-7fdb9acb27ad",
   "metadata": {},
   "source": [
    "# Byte Pair Encoding (BPE)\n",
    "\n",
    "**Descrição:**\n",
    "Este notebook apresenta o funcionamento do **Byte Pair Encoding (BPE)**, um método de tokenização baseado em subpalavras amplamente utilizado em modelos de linguagem modernos. Diferentemente da tokenização por palavras, o BPE constrói tokens a partir de **padrões frequentes de caracteres**, permitindo representar palavras raras ou desconhecidas por meio da combinação de unidades menores.\n",
    "\n",
    "**Objetivo:**\n",
    "Demonstrar, de forma didática e passo a passo, como o algoritmo de Byte Pair Encoding:\n",
    "\n",
    "* Aprende um vocabulário de subpalavras a partir de um corpus\n",
    "* Reduz o problema de palavras fora do vocabulário (OOV)\n",
    "* Cria uma representação compacta e eficiente do texto\n",
    "* Converte texto em sequências de tokens subword (encode)\n",
    "* Reconstrói o texto a partir desses tokens (decode)\n",
    "\n",
    "O objetivo é entender por que o BPE é uma peça fundamental na preparação de texto para o treinamento de LLMs.\n",
    "\n",
    "**Funcionamento:**\n",
    "\n",
    "![Byte pair encoder](../../imagens/cap02/04_byte_pair_encode.png)\n",
    "\n",
    "O funcionamento do BPE segue um processo iterativo de aprendizado e aplicação:\n",
    "\n",
    "1. **Inicialização do vocabulário:**\n",
    "   O texto do corpus é inicialmente representado como sequências de caracteres individuais, geralmente com um marcador de fim de palavra.\n",
    "\n",
    "2. **Aprendizado por fusões (merges):**\n",
    "   O algoritmo identifica o par de símbolos adjacentes mais frequente no corpus e os funde em um novo token.\n",
    "   Esse processo é repetido iterativamente, expandindo gradualmente o vocabulário com subpalavras mais frequentes.\n",
    "\n",
    "3. **Encode (tokenização):**\n",
    "   Um novo texto é decomposto em subpalavras usando as regras de fusão aprendidas, garantindo que qualquer palavra possa ser representada, mesmo que nunca tenha aparecido no corpus original.\n",
    "\n",
    "4. **Decode (reconstrução):**\n",
    "   As sequências de subpalavras são combinadas para reconstruir o texto original, preservando a estrutura das palavras.\n",
    "\n",
    "Esse mecanismo permite que modelos de linguagem equilibrem **tamanho de vocabulário**, **expressividade** e **generalização**, sendo a base de tokenizadores como os usados em GPT, BERT e outros LLMs.\n",
    "\n",
    "**Tokenizadores reais:**\n",
    "\n",
    "* **Open AI** https://platform.openai.com/tokenizer\n",
    "* **Tiktokenizer** https://tiktokenizer.vercel.app/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bf23d1-0f7e-4e11-88e6-515a1197c454",
   "metadata": {},
   "source": [
    "## Implementação de um BPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fc052f9-bcfa-496d-8046-338c2d02c457",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "from collections.abc import Iterable\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class BPEResult:\n",
    "    \"\"\"Armazena resultados do treinamento do BPE (didático).\"\"\"\n",
    "\n",
    "    vocab: dict[tuple[str, ...], int]\n",
    "    merges: list[tuple[str, str]]\n",
    "    token_to_id: dict[str, int]\n",
    "    id_to_token: dict[int, str]\n",
    "\n",
    "\n",
    "class BytePairEncoderDecoder:\n",
    "    \"\"\"\n",
    "    Byte Pair Encoding (BPE) do zero, com passo a passo (didático).\n",
    "\n",
    "    Ideia central (BPE clássico para subpalavras):\n",
    "    - Representamos cada palavra como caracteres + marcador de fim de palavra (</w>)\n",
    "    - Contamos pares adjacentes mais frequentes (bigramas de símbolos)\n",
    "    - Iterativamente \"fundimos\" (merge) o par mais frequente em um novo símbolo\n",
    "    - Guardamos a sequência de merges para tokenizar (encode) textos novos\n",
    "\n",
    "    Observação:\n",
    "    - Este é o BPE \"clássico\" baseado em palavras, suficiente para entender o mecanismo.\n",
    "    - Em tokenizadores modernos (ex.: GPT-2), há detalhes adicionais (bytes, etc.),\n",
    "      mas o coração do BPE (aprender merges frequentes) é o mesmo.\n",
    "    BPE do zero (didático) **considerando pontuação**.\n",
    "\n",
    "    Ajustes principais desta versão:\n",
    "    - A tokenização inicial separa: palavras e pontuação ([,.!?;:])\n",
    "    - Pontuação vira \"tokens atômicos\" (não recebem </w>)\n",
    "    - Palavras recebem caracteres + </w> (fim de palavra), como no BPE clássico\n",
    "    - O decode reconstrói o texto:\n",
    "        * remove </w> e repõe espaços corretamente\n",
    "        * NÃO coloca espaço antes de pontuação\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, end_of_word: str = \"</w>\") -> None:\n",
    "        if not isinstance(end_of_word, str) or not end_of_word:\n",
    "            raise ValueError(\"`end_of_word` deve ser uma string não vazia.\")\n",
    "        self.end_of_word = end_of_word\n",
    "\n",
    "        self.merges: list[tuple[str, str]] = []\n",
    "        self.token_to_id: dict[str, int] = {}\n",
    "        self.id_to_token: dict[int, str] = {}\n",
    "\n",
    "        # Pontuação suportada (didático e suficiente pro seu exemplo)\n",
    "        self._punct = {\".\", \",\", \"!\", \"?\", \";\", \":\"}\n",
    "\n",
    "    # ======================================================\n",
    "    # 1) Tokenização: palavras + pontuação\n",
    "    # ======================================================\n",
    "    def _basic_tokenize_with_punct(self, text: str) -> list[str]:\n",
    "        \"\"\"\n",
    "        Separa palavras e pontuação.\n",
    "\n",
    "        Ex.: \"O gato sobe no tapete.\" -> [\"O\", \"gato\", \"sobe\", \"no\", \"tapete\", \".\"]\n",
    "        \"\"\"\n",
    "        if not isinstance(text, str):\n",
    "            raise TypeError(\"O parâmetro `text` deve ser uma string.\")\n",
    "        if not text.strip():\n",
    "            return []\n",
    "\n",
    "        # Palavras (com acentos) OU pontuação isolada\n",
    "        return re.findall(r\"[A-Za-zÀ-ÿ0-9]+|[,.!?;:]\", text)\n",
    "\n",
    "    def _token_to_symbols(self, token: str) -> tuple[str, ...]:\n",
    "        \"\"\"\n",
    "        Converte um token em símbolos para o BPE:\n",
    "        - Se for pontuação: retorna (token,)\n",
    "        - Se for palavra: retorna (c1, c2, ..., </w>)\n",
    "        \"\"\"\n",
    "        if token in self._punct:\n",
    "            return (token,)\n",
    "        return tuple(list(token) + [self.end_of_word])\n",
    "\n",
    "    # ======================================================\n",
    "    # 2) Construção do vocab inicial (com pontuação)\n",
    "    # ======================================================\n",
    "    def build_initial_vocab(\n",
    "        self, corpus: Iterable[str], verbose: bool = True\n",
    "    ) -> dict[tuple[str, ...], int]:\n",
    "        if corpus is None:\n",
    "            raise TypeError(\"`corpus` não pode ser None.\")\n",
    "\n",
    "        corpus = list(corpus)\n",
    "        if not corpus:\n",
    "            raise ValueError(\"`corpus` precisa conter ao menos 1 frase/texto.\")\n",
    "\n",
    "        vocab: dict[tuple[str, ...], int] = defaultdict(int)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"=== PASSO 1: Corpus bruto ===\")\n",
    "            for i, line in enumerate(corpus, start=1):\n",
    "                print(f\"{i}. {line}\")\n",
    "            print()\n",
    "\n",
    "        if verbose:\n",
    "            print(\"=== PASSO 2: Tokenização (palavras + pontuação) ===\")\n",
    "\n",
    "        all_tokens: list[str] = []\n",
    "        for line in corpus:\n",
    "            toks = self._basic_tokenize_with_punct(line)\n",
    "            all_tokens.extend(toks)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Tokens extraídos:\", all_tokens)\n",
    "            print()\n",
    "\n",
    "        if verbose:\n",
    "            print(\n",
    "                \"=== PASSO 3: Vocabulário inicial (caracteres + </w> | pontuação atômica) ===\"\n",
    "            )\n",
    "\n",
    "        for tok in all_tokens:\n",
    "            sym = self._token_to_symbols(tok)\n",
    "            vocab[sym] += 1\n",
    "\n",
    "        if verbose:\n",
    "            for sym, cnt in sorted(vocab.items(), key=lambda x: (-x[1], x[0])):\n",
    "                print(f\"{' '.join(sym)}  ->  {cnt}\")\n",
    "            print()\n",
    "\n",
    "        return dict(vocab)\n",
    "\n",
    "    # ======================================================\n",
    "    # 3) Contagem de pares e merges (BPE clássico)\n",
    "    # ======================================================\n",
    "    @staticmethod\n",
    "    def _get_pair_frequencies(\n",
    "        vocab: dict[tuple[str, ...], int],\n",
    "    ) -> Counter[tuple[str, str]]:\n",
    "        pairs: Counter[tuple[str, str]] = Counter()\n",
    "        for word_symbols, freq in vocab.items():\n",
    "            if len(word_symbols) < 2:\n",
    "                continue\n",
    "            for i in range(len(word_symbols) - 1):\n",
    "                pairs[(word_symbols[i], word_symbols[i + 1])] += freq\n",
    "        return pairs\n",
    "\n",
    "    @staticmethod\n",
    "    def _merge_pair_in_word(\n",
    "        word_symbols: tuple[str, ...], pair: tuple[str, str]\n",
    "    ) -> tuple[str, ...]:\n",
    "        a, b = pair\n",
    "        merged_symbol = a + b\n",
    "\n",
    "        new_symbols: list[str] = []\n",
    "        i = 0\n",
    "        while i < len(word_symbols):\n",
    "            if (\n",
    "                i < len(word_symbols) - 1\n",
    "                and word_symbols[i] == a\n",
    "                and word_symbols[i + 1] == b\n",
    "            ):\n",
    "                new_symbols.append(merged_symbol)\n",
    "                i += 2\n",
    "            else:\n",
    "                new_symbols.append(word_symbols[i])\n",
    "                i += 1\n",
    "\n",
    "        return tuple(new_symbols)\n",
    "\n",
    "    def train(\n",
    "        self,\n",
    "        corpus: Iterable[str],\n",
    "        num_merges: int = 50,\n",
    "        verbose: bool = True,\n",
    "        top_pairs_to_show: int = 10,\n",
    "    ) -> BPEResult:\n",
    "        if not isinstance(num_merges, int) or num_merges <= 0:\n",
    "            raise ValueError(\"`num_merges` deve ser um inteiro > 0.\")\n",
    "\n",
    "        vocab = self.build_initial_vocab(corpus, verbose=verbose)\n",
    "        self.merges = []\n",
    "\n",
    "        for step in range(1, num_merges + 1):\n",
    "            pairs = self._get_pair_frequencies(vocab)\n",
    "            if not pairs:\n",
    "                if verbose:\n",
    "                    print(\"Nenhum par restante para fundir. Encerrando.\")\n",
    "                break\n",
    "\n",
    "            best_pair, best_freq = pairs.most_common(1)[0]\n",
    "\n",
    "            if verbose:\n",
    "                print(\n",
    "                    f\"=== PASSO 4.{step}: Contagem de pares (top {top_pairs_to_show}) ===\"\n",
    "                )\n",
    "                for p, f in pairs.most_common(top_pairs_to_show):\n",
    "                    print(f\"{p} -> {f}\")\n",
    "                print()\n",
    "                print(f\"=== PASSO 5.{step}: Melhor par para merge ===\")\n",
    "                print(f\"Par escolhido: {best_pair} (freq={best_freq})\")\n",
    "                print(f\"Novo símbolo: '{best_pair[0] + best_pair[1]}'\")\n",
    "                print()\n",
    "\n",
    "            new_vocab: dict[tuple[str, ...], int] = defaultdict(int)\n",
    "            for word_symbols, freq in vocab.items():\n",
    "                merged = self._merge_pair_in_word(word_symbols, best_pair)\n",
    "                new_vocab[merged] += freq\n",
    "\n",
    "            vocab = dict(new_vocab)\n",
    "            self.merges.append(best_pair)\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"=== PASSO 6.{step}: Vocabulário após merge (amostra) ===\")\n",
    "                for sym, cnt in sorted(vocab.items(), key=lambda x: (-x[1], x[0]))[:15]:\n",
    "                    print(f\"{' '.join(sym)}  ->  {cnt}\")\n",
    "                if len(vocab) > 15:\n",
    "                    print(\"... (mostrando apenas 15 entradas)\")\n",
    "                print()\n",
    "\n",
    "        # Tokens finais = todos símbolos que aparecem no vocab final\n",
    "        final_tokens: set[str] = set()\n",
    "        for word_symbols in vocab.keys():\n",
    "            final_tokens.update(word_symbols)\n",
    "\n",
    "        final_tokens_sorted = sorted(final_tokens)\n",
    "        self.token_to_id = {tok: i for i, tok in enumerate(final_tokens_sorted)}\n",
    "        self.id_to_token = {i: tok for tok, i in self.token_to_id.items()}\n",
    "\n",
    "        if verbose:\n",
    "            print(\"=== PASSO 7: Tokens finais (vocabulário de subpalavras) ===\")\n",
    "            print(final_tokens_sorted)\n",
    "            print()\n",
    "\n",
    "        return BPEResult(\n",
    "            vocab=vocab,\n",
    "            merges=self.merges.copy(),\n",
    "            token_to_id=self.token_to_id.copy(),\n",
    "            id_to_token=self.id_to_token.copy(),\n",
    "        )\n",
    "\n",
    "    # ======================================================\n",
    "    # 4) Encode / Decode (com pontuação)\n",
    "    # ======================================================\n",
    "    def _apply_merges_to_symbols(\n",
    "        self, symbols: tuple[str, ...], verbose: bool = True\n",
    "    ) -> tuple[str, ...]:\n",
    "        if verbose:\n",
    "            print(\"Símbolos iniciais:\", symbols)\n",
    "\n",
    "        for i, pair in enumerate(self.merges, start=1):\n",
    "            new_symbols = self._merge_pair_in_word(symbols, pair)\n",
    "            if new_symbols != symbols and verbose:\n",
    "                print(f\"Merge {i}: {pair} -> '{pair[0] + pair[1]}'\")\n",
    "                print(\"Antes:\", symbols)\n",
    "                print(\"Depois:\", new_symbols)\n",
    "                print()\n",
    "            symbols = new_symbols\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Símbolos finais (após merges):\", symbols)\n",
    "            print()\n",
    "\n",
    "        return symbols\n",
    "\n",
    "    def encode(self, text: str, verbose: bool = True) -> list[int]:\n",
    "        if not self.token_to_id or not self.merges:\n",
    "            raise ValueError(\"BPE não treinado. Execute `train()` antes de `encode()`.\")\n",
    "\n",
    "        if verbose:\n",
    "            print(\"=== ENCODE (BPE com pontuação) ===\")\n",
    "            print(\"Texto:\", text)\n",
    "            print()\n",
    "\n",
    "        tokens = self._basic_tokenize_with_punct(text)\n",
    "        if verbose:\n",
    "            print(\"Tokens (palavra/pontuação):\", tokens)\n",
    "            print()\n",
    "\n",
    "        all_ids: list[int] = []\n",
    "        for tok in tokens:\n",
    "            if verbose:\n",
    "                print(f\"--- Token: '{tok}' ---\")\n",
    "            symbols = self._token_to_symbols(tok)\n",
    "            final_symbols = self._apply_merges_to_symbols(symbols, verbose=verbose)\n",
    "\n",
    "            ids = []\n",
    "            for s in final_symbols:\n",
    "                if s not in self.token_to_id:\n",
    "                    raise ValueError(f\"Token '{s}' não existe no vocabulário final.\")\n",
    "                ids.append(self.token_to_id[s])\n",
    "\n",
    "            if verbose:\n",
    "                print(\"Tokens BPE finais:\", final_symbols)\n",
    "                print(\"IDs:\", ids)\n",
    "                print()\n",
    "\n",
    "            all_ids.extend(ids)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"=== SEQUÊNCIA FINAL DE IDS ===\")\n",
    "            print(all_ids)\n",
    "            print()\n",
    "\n",
    "        return all_ids\n",
    "\n",
    "    def decode(self, ids: list[int], verbose: bool = True) -> str:\n",
    "        if not isinstance(ids, list) or any(not isinstance(i, int) for i in ids):\n",
    "            raise TypeError(\"`ids` deve ser uma lista de inteiros (list[int]).\")\n",
    "        if not self.id_to_token:\n",
    "            raise ValueError(\"BPE não treinado. Execute `train()` antes de `decode()`.\")\n",
    "\n",
    "        if verbose:\n",
    "            print(\"=== DECODE (BPE com pontuação) ===\")\n",
    "            print(\"IDs:\", ids)\n",
    "            print()\n",
    "\n",
    "        symbols = []\n",
    "        for i in ids:\n",
    "            if i not in self.id_to_token:\n",
    "                raise ValueError(f\"ID inválido: {i}\")\n",
    "            symbols.append(self.id_to_token[i])\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Símbolos:\", symbols)\n",
    "            print()\n",
    "\n",
    "        # Reconstrução:\n",
    "        # - </w> vira \"separador de palavra\" (um espaço)\n",
    "        # - pontuação não recebe espaço antes\n",
    "        out_parts: list[str] = []\n",
    "        current_word = \"\"\n",
    "\n",
    "        def flush_word() -> None:\n",
    "            nonlocal current_word\n",
    "            if current_word:\n",
    "                out_parts.append(current_word)\n",
    "                current_word = \"\"\n",
    "\n",
    "        for s in symbols:\n",
    "            if s == self.end_of_word:\n",
    "                flush_word()\n",
    "            elif s in self._punct:\n",
    "                # fecha palavra atual e anexa pontuação ao final do texto (sem espaço antes)\n",
    "                flush_word()\n",
    "                if out_parts:\n",
    "                    out_parts[-1] = out_parts[-1] + s\n",
    "                else:\n",
    "                    # caso estranho: pontuação no começo\n",
    "                    out_parts.append(s)\n",
    "            else:\n",
    "                # símbolo normal (subpalavra/char/merge)\n",
    "                current_word += s\n",
    "\n",
    "        flush_word()\n",
    "\n",
    "        text = \" \".join(out_parts).strip()\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Texto reconstruído:\", text)\n",
    "            print()\n",
    "\n",
    "        return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bff797-9ea9-4b42-ba0e-445c253b3d46",
   "metadata": {},
   "source": [
    "## Geração do corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a4cba5f-4d8c-4b84-b2de-15a4ba1a0d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PASSO 1: Corpus bruto ===\n",
      "1. O gato sobe no tapete.\n",
      "2. O cachorro sobe na mesa.\n",
      "3. A aranha desce a parede, e o gato desce da mesa.\n",
      "\n",
      "=== PASSO 2: Tokenização (palavras + pontuação) ===\n",
      "Tokens extraídos: ['O', 'gato', 'sobe', 'no', 'tapete', '.', 'O', 'cachorro', 'sobe', 'na', 'mesa', '.', 'A', 'aranha', 'desce', 'a', 'parede', ',', 'e', 'o', 'gato', 'desce', 'da', 'mesa', '.']\n",
      "\n",
      "=== PASSO 3: Vocabulário inicial (caracteres + </w> | pontuação atômica) ===\n",
      ".  ->  3\n",
      "O </w>  ->  2\n",
      "d e s c e </w>  ->  2\n",
      "g a t o </w>  ->  2\n",
      "m e s a </w>  ->  2\n",
      "s o b e </w>  ->  2\n",
      ",  ->  1\n",
      "A </w>  ->  1\n",
      "a </w>  ->  1\n",
      "a r a n h a </w>  ->  1\n",
      "c a c h o r r o </w>  ->  1\n",
      "d a </w>  ->  1\n",
      "e </w>  ->  1\n",
      "n a </w>  ->  1\n",
      "n o </w>  ->  1\n",
      "o </w>  ->  1\n",
      "p a r e d e </w>  ->  1\n",
      "t a p e t e </w>  ->  1\n",
      "\n",
      "=== PASSO 4.1: Contagem de pares (top 10) ===\n",
      "('e', '</w>') -> 7\n",
      "('a', '</w>') -> 6\n",
      "('o', '</w>') -> 5\n",
      "('e', 's') -> 4\n",
      "('d', 'e') -> 3\n",
      "('O', '</w>') -> 2\n",
      "('g', 'a') -> 2\n",
      "('a', 't') -> 2\n",
      "('t', 'o') -> 2\n",
      "('s', 'o') -> 2\n",
      "\n",
      "=== PASSO 5.1: Melhor par para merge ===\n",
      "Par escolhido: ('e', '</w>') (freq=7)\n",
      "Novo símbolo: 'e</w>'\n",
      "\n",
      "=== PASSO 6.1: Vocabulário após merge (amostra) ===\n",
      ".  ->  3\n",
      "O </w>  ->  2\n",
      "d e s c e</w>  ->  2\n",
      "g a t o </w>  ->  2\n",
      "m e s a </w>  ->  2\n",
      "s o b e</w>  ->  2\n",
      ",  ->  1\n",
      "A </w>  ->  1\n",
      "a </w>  ->  1\n",
      "a r a n h a </w>  ->  1\n",
      "c a c h o r r o </w>  ->  1\n",
      "d a </w>  ->  1\n",
      "e</w>  ->  1\n",
      "n a </w>  ->  1\n",
      "n o </w>  ->  1\n",
      "... (mostrando apenas 15 entradas)\n",
      "\n",
      "=== PASSO 4.2: Contagem de pares (top 10) ===\n",
      "('a', '</w>') -> 6\n",
      "('o', '</w>') -> 5\n",
      "('e', 's') -> 4\n",
      "('O', '</w>') -> 2\n",
      "('g', 'a') -> 2\n",
      "('a', 't') -> 2\n",
      "('t', 'o') -> 2\n",
      "('s', 'o') -> 2\n",
      "('o', 'b') -> 2\n",
      "('b', 'e</w>') -> 2\n",
      "\n",
      "=== PASSO 5.2: Melhor par para merge ===\n",
      "Par escolhido: ('a', '</w>') (freq=6)\n",
      "Novo símbolo: 'a</w>'\n",
      "\n",
      "=== PASSO 6.2: Vocabulário após merge (amostra) ===\n",
      ".  ->  3\n",
      "O </w>  ->  2\n",
      "d e s c e</w>  ->  2\n",
      "g a t o </w>  ->  2\n",
      "m e s a</w>  ->  2\n",
      "s o b e</w>  ->  2\n",
      ",  ->  1\n",
      "A </w>  ->  1\n",
      "a r a n h a</w>  ->  1\n",
      "a</w>  ->  1\n",
      "c a c h o r r o </w>  ->  1\n",
      "d a</w>  ->  1\n",
      "e</w>  ->  1\n",
      "n a</w>  ->  1\n",
      "n o </w>  ->  1\n",
      "... (mostrando apenas 15 entradas)\n",
      "\n",
      "=== PASSO 4.3: Contagem de pares (top 10) ===\n",
      "('o', '</w>') -> 5\n",
      "('e', 's') -> 4\n",
      "('O', '</w>') -> 2\n",
      "('g', 'a') -> 2\n",
      "('a', 't') -> 2\n",
      "('t', 'o') -> 2\n",
      "('s', 'o') -> 2\n",
      "('o', 'b') -> 2\n",
      "('b', 'e</w>') -> 2\n",
      "('m', 'e') -> 2\n",
      "\n",
      "=== PASSO 5.3: Melhor par para merge ===\n",
      "Par escolhido: ('o', '</w>') (freq=5)\n",
      "Novo símbolo: 'o</w>'\n",
      "\n",
      "=== PASSO 6.3: Vocabulário após merge (amostra) ===\n",
      ".  ->  3\n",
      "O </w>  ->  2\n",
      "d e s c e</w>  ->  2\n",
      "g a t o</w>  ->  2\n",
      "m e s a</w>  ->  2\n",
      "s o b e</w>  ->  2\n",
      ",  ->  1\n",
      "A </w>  ->  1\n",
      "a r a n h a</w>  ->  1\n",
      "a</w>  ->  1\n",
      "c a c h o r r o</w>  ->  1\n",
      "d a</w>  ->  1\n",
      "e</w>  ->  1\n",
      "n a</w>  ->  1\n",
      "n o</w>  ->  1\n",
      "... (mostrando apenas 15 entradas)\n",
      "\n",
      "=== PASSO 4.4: Contagem de pares (top 10) ===\n",
      "('e', 's') -> 4\n",
      "('O', '</w>') -> 2\n",
      "('g', 'a') -> 2\n",
      "('a', 't') -> 2\n",
      "('t', 'o</w>') -> 2\n",
      "('s', 'o') -> 2\n",
      "('o', 'b') -> 2\n",
      "('b', 'e</w>') -> 2\n",
      "('m', 'e') -> 2\n",
      "('s', 'a</w>') -> 2\n",
      "\n",
      "=== PASSO 5.4: Melhor par para merge ===\n",
      "Par escolhido: ('e', 's') (freq=4)\n",
      "Novo símbolo: 'es'\n",
      "\n",
      "=== PASSO 6.4: Vocabulário após merge (amostra) ===\n",
      ".  ->  3\n",
      "O </w>  ->  2\n",
      "d es c e</w>  ->  2\n",
      "g a t o</w>  ->  2\n",
      "m es a</w>  ->  2\n",
      "s o b e</w>  ->  2\n",
      ",  ->  1\n",
      "A </w>  ->  1\n",
      "a r a n h a</w>  ->  1\n",
      "a</w>  ->  1\n",
      "c a c h o r r o</w>  ->  1\n",
      "d a</w>  ->  1\n",
      "e</w>  ->  1\n",
      "n a</w>  ->  1\n",
      "n o</w>  ->  1\n",
      "... (mostrando apenas 15 entradas)\n",
      "\n",
      "=== PASSO 4.5: Contagem de pares (top 10) ===\n",
      "('O', '</w>') -> 2\n",
      "('g', 'a') -> 2\n",
      "('a', 't') -> 2\n",
      "('t', 'o</w>') -> 2\n",
      "('s', 'o') -> 2\n",
      "('o', 'b') -> 2\n",
      "('b', 'e</w>') -> 2\n",
      "('m', 'es') -> 2\n",
      "('es', 'a</w>') -> 2\n",
      "('a', 'r') -> 2\n",
      "\n",
      "=== PASSO 5.5: Melhor par para merge ===\n",
      "Par escolhido: ('O', '</w>') (freq=2)\n",
      "Novo símbolo: 'O</w>'\n",
      "\n",
      "=== PASSO 6.5: Vocabulário após merge (amostra) ===\n",
      ".  ->  3\n",
      "O</w>  ->  2\n",
      "d es c e</w>  ->  2\n",
      "g a t o</w>  ->  2\n",
      "m es a</w>  ->  2\n",
      "s o b e</w>  ->  2\n",
      ",  ->  1\n",
      "A </w>  ->  1\n",
      "a r a n h a</w>  ->  1\n",
      "a</w>  ->  1\n",
      "c a c h o r r o</w>  ->  1\n",
      "d a</w>  ->  1\n",
      "e</w>  ->  1\n",
      "n a</w>  ->  1\n",
      "n o</w>  ->  1\n",
      "... (mostrando apenas 15 entradas)\n",
      "\n",
      "=== PASSO 4.6: Contagem de pares (top 10) ===\n",
      "('g', 'a') -> 2\n",
      "('a', 't') -> 2\n",
      "('t', 'o</w>') -> 2\n",
      "('s', 'o') -> 2\n",
      "('o', 'b') -> 2\n",
      "('b', 'e</w>') -> 2\n",
      "('m', 'es') -> 2\n",
      "('es', 'a</w>') -> 2\n",
      "('a', 'r') -> 2\n",
      "('d', 'es') -> 2\n",
      "\n",
      "=== PASSO 5.6: Melhor par para merge ===\n",
      "Par escolhido: ('g', 'a') (freq=2)\n",
      "Novo símbolo: 'ga'\n",
      "\n",
      "=== PASSO 6.6: Vocabulário após merge (amostra) ===\n",
      ".  ->  3\n",
      "O</w>  ->  2\n",
      "d es c e</w>  ->  2\n",
      "ga t o</w>  ->  2\n",
      "m es a</w>  ->  2\n",
      "s o b e</w>  ->  2\n",
      ",  ->  1\n",
      "A </w>  ->  1\n",
      "a r a n h a</w>  ->  1\n",
      "a</w>  ->  1\n",
      "c a c h o r r o</w>  ->  1\n",
      "d a</w>  ->  1\n",
      "e</w>  ->  1\n",
      "n a</w>  ->  1\n",
      "n o</w>  ->  1\n",
      "... (mostrando apenas 15 entradas)\n",
      "\n",
      "=== PASSO 4.7: Contagem de pares (top 10) ===\n",
      "('ga', 't') -> 2\n",
      "('t', 'o</w>') -> 2\n",
      "('s', 'o') -> 2\n",
      "('o', 'b') -> 2\n",
      "('b', 'e</w>') -> 2\n",
      "('m', 'es') -> 2\n",
      "('es', 'a</w>') -> 2\n",
      "('a', 'r') -> 2\n",
      "('d', 'es') -> 2\n",
      "('es', 'c') -> 2\n",
      "\n",
      "=== PASSO 5.7: Melhor par para merge ===\n",
      "Par escolhido: ('ga', 't') (freq=2)\n",
      "Novo símbolo: 'gat'\n",
      "\n",
      "=== PASSO 6.7: Vocabulário após merge (amostra) ===\n",
      ".  ->  3\n",
      "O</w>  ->  2\n",
      "d es c e</w>  ->  2\n",
      "gat o</w>  ->  2\n",
      "m es a</w>  ->  2\n",
      "s o b e</w>  ->  2\n",
      ",  ->  1\n",
      "A </w>  ->  1\n",
      "a r a n h a</w>  ->  1\n",
      "a</w>  ->  1\n",
      "c a c h o r r o</w>  ->  1\n",
      "d a</w>  ->  1\n",
      "e</w>  ->  1\n",
      "n a</w>  ->  1\n",
      "n o</w>  ->  1\n",
      "... (mostrando apenas 15 entradas)\n",
      "\n",
      "=== PASSO 4.8: Contagem de pares (top 10) ===\n",
      "('gat', 'o</w>') -> 2\n",
      "('s', 'o') -> 2\n",
      "('o', 'b') -> 2\n",
      "('b', 'e</w>') -> 2\n",
      "('m', 'es') -> 2\n",
      "('es', 'a</w>') -> 2\n",
      "('a', 'r') -> 2\n",
      "('d', 'es') -> 2\n",
      "('es', 'c') -> 2\n",
      "('c', 'e</w>') -> 2\n",
      "\n",
      "=== PASSO 5.8: Melhor par para merge ===\n",
      "Par escolhido: ('gat', 'o</w>') (freq=2)\n",
      "Novo símbolo: 'gato</w>'\n",
      "\n",
      "=== PASSO 6.8: Vocabulário após merge (amostra) ===\n",
      ".  ->  3\n",
      "O</w>  ->  2\n",
      "d es c e</w>  ->  2\n",
      "gato</w>  ->  2\n",
      "m es a</w>  ->  2\n",
      "s o b e</w>  ->  2\n",
      ",  ->  1\n",
      "A </w>  ->  1\n",
      "a r a n h a</w>  ->  1\n",
      "a</w>  ->  1\n",
      "c a c h o r r o</w>  ->  1\n",
      "d a</w>  ->  1\n",
      "e</w>  ->  1\n",
      "n a</w>  ->  1\n",
      "n o</w>  ->  1\n",
      "... (mostrando apenas 15 entradas)\n",
      "\n",
      "=== PASSO 4.9: Contagem de pares (top 10) ===\n",
      "('s', 'o') -> 2\n",
      "('o', 'b') -> 2\n",
      "('b', 'e</w>') -> 2\n",
      "('m', 'es') -> 2\n",
      "('es', 'a</w>') -> 2\n",
      "('a', 'r') -> 2\n",
      "('d', 'es') -> 2\n",
      "('es', 'c') -> 2\n",
      "('c', 'e</w>') -> 2\n",
      "('n', 'o</w>') -> 1\n",
      "\n",
      "=== PASSO 5.9: Melhor par para merge ===\n",
      "Par escolhido: ('s', 'o') (freq=2)\n",
      "Novo símbolo: 'so'\n",
      "\n",
      "=== PASSO 6.9: Vocabulário após merge (amostra) ===\n",
      ".  ->  3\n",
      "O</w>  ->  2\n",
      "d es c e</w>  ->  2\n",
      "gato</w>  ->  2\n",
      "m es a</w>  ->  2\n",
      "so b e</w>  ->  2\n",
      ",  ->  1\n",
      "A </w>  ->  1\n",
      "a r a n h a</w>  ->  1\n",
      "a</w>  ->  1\n",
      "c a c h o r r o</w>  ->  1\n",
      "d a</w>  ->  1\n",
      "e</w>  ->  1\n",
      "n a</w>  ->  1\n",
      "n o</w>  ->  1\n",
      "... (mostrando apenas 15 entradas)\n",
      "\n",
      "=== PASSO 4.10: Contagem de pares (top 10) ===\n",
      "('so', 'b') -> 2\n",
      "('b', 'e</w>') -> 2\n",
      "('m', 'es') -> 2\n",
      "('es', 'a</w>') -> 2\n",
      "('a', 'r') -> 2\n",
      "('d', 'es') -> 2\n",
      "('es', 'c') -> 2\n",
      "('c', 'e</w>') -> 2\n",
      "('n', 'o</w>') -> 1\n",
      "('t', 'a') -> 1\n",
      "\n",
      "=== PASSO 5.10: Melhor par para merge ===\n",
      "Par escolhido: ('so', 'b') (freq=2)\n",
      "Novo símbolo: 'sob'\n",
      "\n",
      "=== PASSO 6.10: Vocabulário após merge (amostra) ===\n",
      ".  ->  3\n",
      "O</w>  ->  2\n",
      "d es c e</w>  ->  2\n",
      "gato</w>  ->  2\n",
      "m es a</w>  ->  2\n",
      "sob e</w>  ->  2\n",
      ",  ->  1\n",
      "A </w>  ->  1\n",
      "a r a n h a</w>  ->  1\n",
      "a</w>  ->  1\n",
      "c a c h o r r o</w>  ->  1\n",
      "d a</w>  ->  1\n",
      "e</w>  ->  1\n",
      "n a</w>  ->  1\n",
      "n o</w>  ->  1\n",
      "... (mostrando apenas 15 entradas)\n",
      "\n",
      "=== PASSO 7: Tokens finais (vocabulário de subpalavras) ===\n",
      "[',', '.', '</w>', 'A', 'O</w>', 'a', 'a</w>', 'c', 'd', 'e', 'e</w>', 'es', 'gato</w>', 'h', 'm', 'n', 'o', 'o</w>', 'p', 'r', 'sob', 't']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "corpus = [\n",
    "    \"O gato sobe no tapete.\",\n",
    "    \"O cachorro sobe na mesa.\",\n",
    "    \"A aranha desce a parede, e o gato desce da mesa.\",\n",
    "]\n",
    "\n",
    "bpe = BytePairEncoderDecoder(end_of_word=\"</w>\")\n",
    "\n",
    "# Treinar com poucas merges para ficar bem visível no passo a passo\n",
    "resultado = bpe.train(corpus=corpus, num_merges=10, verbose=True, top_pairs_to_show=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce7f2231-d137-40e0-bb52-b946de825a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{',': 0,\n",
       " '.': 1,\n",
       " '</w>': 2,\n",
       " 'A': 3,\n",
       " 'O</w>': 4,\n",
       " 'a': 5,\n",
       " 'a</w>': 6,\n",
       " 'c': 7,\n",
       " 'd': 8,\n",
       " 'e': 9,\n",
       " 'e</w>': 10,\n",
       " 'es': 11,\n",
       " 'gato</w>': 12,\n",
       " 'h': 13,\n",
       " 'm': 14,\n",
       " 'n': 15,\n",
       " 'o': 16,\n",
       " 'o</w>': 17,\n",
       " 'p': 18,\n",
       " 'r': 19,\n",
       " 'sob': 20,\n",
       " 't': 21}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado.token_to_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fa2f29-2838-44a8-9f6a-f51a9ef9b445",
   "metadata": {},
   "source": [
    "## Exemplo de uso do encode (uma frase ainda não utilizada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfd08a99-666c-4fb2-9fcc-d750cde30a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ENCODE (BPE com pontuação) ===\n",
      "Texto: A aranha sobe no gato.\n",
      "\n",
      "Tokens (palavra/pontuação): ['A', 'aranha', 'sobe', 'no', 'gato', '.']\n",
      "\n",
      "--- Token: 'A' ---\n",
      "Símbolos iniciais: ('A', '</w>')\n",
      "Símbolos finais (após merges): ('A', '</w>')\n",
      "\n",
      "Tokens BPE finais: ('A', '</w>')\n",
      "IDs: [3, 2]\n",
      "\n",
      "--- Token: 'aranha' ---\n",
      "Símbolos iniciais: ('a', 'r', 'a', 'n', 'h', 'a', '</w>')\n",
      "Merge 2: ('a', '</w>') -> 'a</w>'\n",
      "Antes: ('a', 'r', 'a', 'n', 'h', 'a', '</w>')\n",
      "Depois: ('a', 'r', 'a', 'n', 'h', 'a</w>')\n",
      "\n",
      "Símbolos finais (após merges): ('a', 'r', 'a', 'n', 'h', 'a</w>')\n",
      "\n",
      "Tokens BPE finais: ('a', 'r', 'a', 'n', 'h', 'a</w>')\n",
      "IDs: [5, 19, 5, 15, 13, 6]\n",
      "\n",
      "--- Token: 'sobe' ---\n",
      "Símbolos iniciais: ('s', 'o', 'b', 'e', '</w>')\n",
      "Merge 1: ('e', '</w>') -> 'e</w>'\n",
      "Antes: ('s', 'o', 'b', 'e', '</w>')\n",
      "Depois: ('s', 'o', 'b', 'e</w>')\n",
      "\n",
      "Merge 9: ('s', 'o') -> 'so'\n",
      "Antes: ('s', 'o', 'b', 'e</w>')\n",
      "Depois: ('so', 'b', 'e</w>')\n",
      "\n",
      "Merge 10: ('so', 'b') -> 'sob'\n",
      "Antes: ('so', 'b', 'e</w>')\n",
      "Depois: ('sob', 'e</w>')\n",
      "\n",
      "Símbolos finais (após merges): ('sob', 'e</w>')\n",
      "\n",
      "Tokens BPE finais: ('sob', 'e</w>')\n",
      "IDs: [20, 10]\n",
      "\n",
      "--- Token: 'no' ---\n",
      "Símbolos iniciais: ('n', 'o', '</w>')\n",
      "Merge 3: ('o', '</w>') -> 'o</w>'\n",
      "Antes: ('n', 'o', '</w>')\n",
      "Depois: ('n', 'o</w>')\n",
      "\n",
      "Símbolos finais (após merges): ('n', 'o</w>')\n",
      "\n",
      "Tokens BPE finais: ('n', 'o</w>')\n",
      "IDs: [15, 17]\n",
      "\n",
      "--- Token: 'gato' ---\n",
      "Símbolos iniciais: ('g', 'a', 't', 'o', '</w>')\n",
      "Merge 3: ('o', '</w>') -> 'o</w>'\n",
      "Antes: ('g', 'a', 't', 'o', '</w>')\n",
      "Depois: ('g', 'a', 't', 'o</w>')\n",
      "\n",
      "Merge 6: ('g', 'a') -> 'ga'\n",
      "Antes: ('g', 'a', 't', 'o</w>')\n",
      "Depois: ('ga', 't', 'o</w>')\n",
      "\n",
      "Merge 7: ('ga', 't') -> 'gat'\n",
      "Antes: ('ga', 't', 'o</w>')\n",
      "Depois: ('gat', 'o</w>')\n",
      "\n",
      "Merge 8: ('gat', 'o</w>') -> 'gato</w>'\n",
      "Antes: ('gat', 'o</w>')\n",
      "Depois: ('gato</w>',)\n",
      "\n",
      "Símbolos finais (após merges): ('gato</w>',)\n",
      "\n",
      "Tokens BPE finais: ('gato</w>',)\n",
      "IDs: [12]\n",
      "\n",
      "--- Token: '.' ---\n",
      "Símbolos iniciais: ('.',)\n",
      "Símbolos finais (após merges): ('.',)\n",
      "\n",
      "Tokens BPE finais: ('.',)\n",
      "IDs: [1]\n",
      "\n",
      "=== SEQUÊNCIA FINAL DE IDS ===\n",
      "[3, 2, 5, 19, 5, 15, 13, 6, 20, 10, 15, 17, 12, 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Encode: veja como palavras viram subpalavras/bytes (aqui: símbolos BPE)\n",
    "texto_novo = \"A aranha sobe no gato.\"\n",
    "ids = bpe.encode(texto_novo, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fd7301-306f-4c8c-a564-5783e725203a",
   "metadata": {},
   "source": [
    "## Exemplo de uso do decode (Uma frase ainda não utilizada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "645892f6-8576-4c54-88ca-4c0a7e28bdd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DECODE (BPE com pontuação) ===\n",
      "IDs: [3, 2, 5, 19, 5, 15, 13, 6, 20, 10, 15, 17, 12, 1]\n",
      "\n",
      "Símbolos: ['A', '</w>', 'a', 'r', 'a', 'n', 'h', 'a</w>', 'sob', 'e</w>', 'n', 'o</w>', 'gato</w>', '.']\n",
      "\n",
      "Texto reconstruído: A aranha</w>sobe</w>no</w>gato</w>.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decode: volta ao texto\n",
    "texto_reconstruido = bpe.decode(ids, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56366a67-ebd0-436d-8532-5671b8ab6c09",
   "metadata": {},
   "source": [
    "## Este método é naturalmente robusto a palavras desconhecidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3328d858-9934-4ad0-bce3-c390b43f2589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ENCODE (BPE com pontuação) ===\n",
      "Texto: A aranha sobe no rato.\n",
      "\n",
      "Tokens (palavra/pontuação): ['A', 'aranha', 'sobe', 'no', 'rato', '.']\n",
      "\n",
      "--- Token: 'A' ---\n",
      "Símbolos iniciais: ('A', '</w>')\n",
      "Símbolos finais (após merges): ('A', '</w>')\n",
      "\n",
      "Tokens BPE finais: ('A', '</w>')\n",
      "IDs: [3, 2]\n",
      "\n",
      "--- Token: 'aranha' ---\n",
      "Símbolos iniciais: ('a', 'r', 'a', 'n', 'h', 'a', '</w>')\n",
      "Merge 2: ('a', '</w>') -> 'a</w>'\n",
      "Antes: ('a', 'r', 'a', 'n', 'h', 'a', '</w>')\n",
      "Depois: ('a', 'r', 'a', 'n', 'h', 'a</w>')\n",
      "\n",
      "Símbolos finais (após merges): ('a', 'r', 'a', 'n', 'h', 'a</w>')\n",
      "\n",
      "Tokens BPE finais: ('a', 'r', 'a', 'n', 'h', 'a</w>')\n",
      "IDs: [5, 19, 5, 15, 13, 6]\n",
      "\n",
      "--- Token: 'sobe' ---\n",
      "Símbolos iniciais: ('s', 'o', 'b', 'e', '</w>')\n",
      "Merge 1: ('e', '</w>') -> 'e</w>'\n",
      "Antes: ('s', 'o', 'b', 'e', '</w>')\n",
      "Depois: ('s', 'o', 'b', 'e</w>')\n",
      "\n",
      "Merge 9: ('s', 'o') -> 'so'\n",
      "Antes: ('s', 'o', 'b', 'e</w>')\n",
      "Depois: ('so', 'b', 'e</w>')\n",
      "\n",
      "Merge 10: ('so', 'b') -> 'sob'\n",
      "Antes: ('so', 'b', 'e</w>')\n",
      "Depois: ('sob', 'e</w>')\n",
      "\n",
      "Símbolos finais (após merges): ('sob', 'e</w>')\n",
      "\n",
      "Tokens BPE finais: ('sob', 'e</w>')\n",
      "IDs: [20, 10]\n",
      "\n",
      "--- Token: 'no' ---\n",
      "Símbolos iniciais: ('n', 'o', '</w>')\n",
      "Merge 3: ('o', '</w>') -> 'o</w>'\n",
      "Antes: ('n', 'o', '</w>')\n",
      "Depois: ('n', 'o</w>')\n",
      "\n",
      "Símbolos finais (após merges): ('n', 'o</w>')\n",
      "\n",
      "Tokens BPE finais: ('n', 'o</w>')\n",
      "IDs: [15, 17]\n",
      "\n",
      "--- Token: 'rato' ---\n",
      "Símbolos iniciais: ('r', 'a', 't', 'o', '</w>')\n",
      "Merge 3: ('o', '</w>') -> 'o</w>'\n",
      "Antes: ('r', 'a', 't', 'o', '</w>')\n",
      "Depois: ('r', 'a', 't', 'o</w>')\n",
      "\n",
      "Símbolos finais (após merges): ('r', 'a', 't', 'o</w>')\n",
      "\n",
      "Tokens BPE finais: ('r', 'a', 't', 'o</w>')\n",
      "IDs: [19, 5, 21, 17]\n",
      "\n",
      "--- Token: '.' ---\n",
      "Símbolos iniciais: ('.',)\n",
      "Símbolos finais (após merges): ('.',)\n",
      "\n",
      "Tokens BPE finais: ('.',)\n",
      "IDs: [1]\n",
      "\n",
      "=== SEQUÊNCIA FINAL DE IDS ===\n",
      "[3, 2, 5, 19, 5, 15, 13, 6, 20, 10, 15, 17, 19, 5, 21, 17, 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Encode: veja como palavras viram subpalavras/bytes (aqui: símbolos BPE)\n",
    "texto_novo = \"A aranha sobe no rato.\"\n",
    "ids = bpe.encode(texto_novo, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be8d324-5ff7-4cf5-8543-5ce5c7c7ea6d",
   "metadata": {},
   "source": [
    "## Decode com a palavra desconhecida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b294d3c9-d1e2-4cde-832d-6f1ba29e655f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DECODE (BPE com pontuação) ===\n",
      "IDs: [3, 2, 5, 19, 5, 15, 13, 6, 20, 10, 15, 17, 19, 5, 21, 17, 1]\n",
      "\n",
      "Símbolos: ['A', '</w>', 'a', 'r', 'a', 'n', 'h', 'a</w>', 'sob', 'e</w>', 'n', 'o</w>', 'r', 'a', 't', 'o</w>', '.']\n",
      "\n",
      "Texto reconstruído: A aranha</w>sobe</w>no</w>rato</w>.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decode: volta ao texto\n",
    "texto_reconstruido = bpe.decode(ids, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc7774d-88c5-4f14-af28-659384d8450b",
   "metadata": {},
   "source": [
    "## O número de iterações influencia nos tokens gerados\n",
    "\n",
    "### Iterações = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2de7e2aa-3e08-4cbe-82d4-3af0299be972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.': 0,\n",
       " '</w>': 1,\n",
       " 'A': 2,\n",
       " 'O': 3,\n",
       " 'a': 4,\n",
       " 'b': 5,\n",
       " 'c': 6,\n",
       " 'd': 7,\n",
       " 'e': 8,\n",
       " 'e</w>': 9,\n",
       " 'g': 10,\n",
       " 'h': 11,\n",
       " 'm': 12,\n",
       " 'n': 13,\n",
       " 'o': 14,\n",
       " 'p': 15,\n",
       " 'r': 16,\n",
       " 's': 17,\n",
       " 't': 18}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [\n",
    "    \"O gato sobe no tapete.\",\n",
    "    \"O cachorro sobe na mesa.\",\n",
    "    \"A aranha desce a parede.\",\n",
    "    \"O gato desce da mesa.\",\n",
    "]\n",
    "\n",
    "bpe = BytePairEncoderDecoder(end_of_word=\"</w>\")\n",
    "resultado = bpe.train(corpus=corpus, num_merges=1, verbose=False)\n",
    "resultado.token_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3eca331-5d01-47f0-a3cc-bd1ebc531a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(texto_novo)=45\n",
      "ids=[3, 1, 10, 4, 18, 14, 1, 17, 14, 5, 9, 13, 14, 1, 18, 4, 15, 8, 18, 9, 3, 1, 6, 4, 6, 11, 14, 16, 16, 14, 1, 17, 14, 5, 9, 13, 4, 1, 12, 8, 17, 4, 1], len(ids)=43\n"
     ]
    }
   ],
   "source": [
    "texto_novo = \"O gato sobe no tapete O cachorro sobe na mesa\"\n",
    "print(f\"{len(texto_novo)=}\")\n",
    "ids = bpe.encode(texto_novo, verbose=False)\n",
    "print(f\"{ids=}, {len(ids)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ba54b0b-b769-423a-9e2f-7dd6a12ea700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0444444444444444"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxa_compressao = 1 - (len(ids) / len(texto_novo))\n",
    "taxa_compressao"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6482b868-4de4-4a2d-907f-a769ad6be571",
   "metadata": {},
   "source": [
    "### Iterações = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b38e235c-2940-4819-95e1-c56f9c83c3f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.': 0,\n",
       " '</w>': 1,\n",
       " 'A': 2,\n",
       " 'O</w>': 3,\n",
       " 'a': 4,\n",
       " 'a</w>': 5,\n",
       " 'ar': 6,\n",
       " 'c': 7,\n",
       " 'd': 8,\n",
       " 'desce</w>': 9,\n",
       " 'e': 10,\n",
       " 'e</w>': 11,\n",
       " 'gato</w>': 12,\n",
       " 'h': 13,\n",
       " 'mesa</w>': 14,\n",
       " 'n': 15,\n",
       " 'no</w>': 16,\n",
       " 'o': 17,\n",
       " 'o</w>': 18,\n",
       " 'p': 19,\n",
       " 'r': 20,\n",
       " 'sobe</w>': 21,\n",
       " 't': 22,\n",
       " 'tap': 23}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe = BytePairEncoderDecoder(end_of_word=\"</w>\")\n",
    "resultado = bpe.train(corpus=corpus, num_merges=20, verbose=False)\n",
    "resultado.token_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7003e641-4f11-46e8-817b-7d69ab3b68c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(texto_novo)=46\n",
      "ids=[3, 12, 21, 16, 23, 10, 22, 11, 3, 7, 4, 7, 13, 17, 20, 20, 18, 21, 15, 5, 14, 0], len(ids)=22\n"
     ]
    }
   ],
   "source": [
    "texto_novo = \"O gato sobe no tapete O cachorro sobe na mesa.\"\n",
    "print(f\"{len(texto_novo)=}\")\n",
    "ids = bpe.encode(texto_novo, verbose=False)\n",
    "print(f\"{ids=}, {len(ids)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9dfba507-9ffe-4085-ab29-da4de29f4142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5217391304347826"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxa_compressao = 1 - (len(ids) / len(texto_novo))\n",
    "taxa_compressao"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3233303a-77f1-422d-8813-6fb50fb256a5",
   "metadata": {},
   "source": [
    "### Iterações = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "daaf997f-3a01-4123-9184-01a2718c5d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.': 0,\n",
       " 'A</w>': 1,\n",
       " 'O</w>': 2,\n",
       " 'a</w>': 3,\n",
       " 'aranha</w>': 4,\n",
       " 'cachorro</w>': 5,\n",
       " 'd': 6,\n",
       " 'desce</w>': 7,\n",
       " 'gato</w>': 8,\n",
       " 'mesa</w>': 9,\n",
       " 'na</w>': 10,\n",
       " 'no</w>': 11,\n",
       " 'parede</w>': 12,\n",
       " 'sobe</w>': 13,\n",
       " 'tapete</w>': 14}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe = BytePairEncoderDecoder(end_of_word=\"</w>\")\n",
    "resultado = bpe.train(corpus=corpus, num_merges=40, verbose=False)\n",
    "resultado.token_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8220f274-33be-4406-8dbf-4cb169c756d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(texto_novo)=45\n",
      "ids=[2, 8, 13, 11, 14, 2, 5, 13, 10, 9], len(ids)=10\n"
     ]
    }
   ],
   "source": [
    "texto_novo = \"O gato sobe no tapete O cachorro sobe na mesa\"\n",
    "print(f\"{len(texto_novo)=}\")\n",
    "ids = bpe.encode(texto_novo, verbose=False)\n",
    "print(f\"{ids=}, {len(ids)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d285ddf8-684f-4dd3-8d6a-a004a1437fe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7777777777777778"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxa_compressao = 1 - (len(ids) / len(texto_novo))\n",
    "taxa_compressao"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08443f3-6c4e-418c-837b-932073b96ee1",
   "metadata": {},
   "source": [
    "## Taxa de compressão para textos muito repetitivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a528238-9c2d-4345-8c2a-9596bd35b89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PASSO 1: Corpus bruto ===\n",
      "1. ando\n",
      "2. andas\n",
      "3. anda\n",
      "4. andamos\n",
      "5. andais\n",
      "6. andam\n",
      "7. andei\n",
      "8. andaste\n",
      "9. andou\n",
      "10. andamos\n",
      "11. andastes\n",
      "12. andaram\n",
      "13. andava\n",
      "14. andavas\n",
      "15. andava\n",
      "16. andávamos\n",
      "17. andáveis\n",
      "18. andavam\n",
      "19. andarei\n",
      "20. andarás\n",
      "21. andará\n",
      "22. andaremos\n",
      "23. andareis\n",
      "24. andarão\n",
      "25. andaria\n",
      "26. andarias\n",
      "27. andaria\n",
      "28. andaríamos\n",
      "29. andaríeis\n",
      "30. andariam\n",
      "31. ande\n",
      "32. andes\n",
      "33. ande\n",
      "34. andemos\n",
      "35. andeis\n",
      "36. andem\n",
      "37. anda\n",
      "38. ande\n",
      "39. andemos\n",
      "40. andai\n",
      "41. andem\n",
      "\n",
      "=== PASSO 2: Tokenização (palavras + pontuação) ===\n",
      "Tokens extraídos: ['ando', 'andas', 'anda', 'andamos', 'andais', 'andam', 'andei', 'andaste', 'andou', 'andamos', 'andastes', 'andaram', 'andava', 'andavas', 'andava', 'andávamos', 'andáveis', 'andavam', 'andarei', 'andarás', 'andará', 'andaremos', 'andareis', 'andarão', 'andaria', 'andarias', 'andaria', 'andaríamos', 'andaríeis', 'andariam', 'ande', 'andes', 'ande', 'andemos', 'andeis', 'andem', 'anda', 'ande', 'andemos', 'andai', 'andem']\n",
      "\n",
      "=== PASSO 3: Vocabulário inicial (caracteres + </w> | pontuação atômica) ===\n",
      "a n d e </w>  ->  3\n",
      "a n d a </w>  ->  2\n",
      "a n d a m o s </w>  ->  2\n",
      "a n d a r i a </w>  ->  2\n",
      "a n d a v a </w>  ->  2\n",
      "a n d e m </w>  ->  2\n",
      "a n d e m o s </w>  ->  2\n",
      "a n d a i </w>  ->  1\n",
      "a n d a i s </w>  ->  1\n",
      "a n d a m </w>  ->  1\n",
      "a n d a r a m </w>  ->  1\n",
      "a n d a r e i </w>  ->  1\n",
      "a n d a r e i s </w>  ->  1\n",
      "a n d a r e m o s </w>  ->  1\n",
      "a n d a r i a m </w>  ->  1\n",
      "a n d a r i a s </w>  ->  1\n",
      "a n d a r á </w>  ->  1\n",
      "a n d a r á s </w>  ->  1\n",
      "a n d a r ã o </w>  ->  1\n",
      "a n d a r í a m o s </w>  ->  1\n",
      "a n d a r í e i s </w>  ->  1\n",
      "a n d a s </w>  ->  1\n",
      "a n d a s t e </w>  ->  1\n",
      "a n d a s t e s </w>  ->  1\n",
      "a n d a v a m </w>  ->  1\n",
      "a n d a v a s </w>  ->  1\n",
      "a n d e i </w>  ->  1\n",
      "a n d e i s </w>  ->  1\n",
      "a n d e s </w>  ->  1\n",
      "a n d o </w>  ->  1\n",
      "a n d o u </w>  ->  1\n",
      "a n d á v a m o s </w>  ->  1\n",
      "a n d á v e i s </w>  ->  1\n",
      "\n",
      "=== PASSO 4.1: Contagem de pares (top 10) ===\n",
      "('a', 'n') -> 41\n",
      "('n', 'd') -> 41\n",
      "('d', 'a') -> 27\n",
      "('s', '</w>') -> 18\n",
      "('a', 'r') -> 13\n",
      "('d', 'e') -> 10\n",
      "('a', 'm') -> 8\n",
      "('m', 'o') -> 7\n",
      "('o', 's') -> 7\n",
      "('a', '</w>') -> 6\n",
      "\n",
      "=== PASSO 5.1: Melhor par para merge ===\n",
      "Par escolhido: ('a', 'n') (freq=41)\n",
      "Novo símbolo: 'an'\n",
      "\n",
      "=== PASSO 6.1: Vocabulário após merge (amostra) ===\n",
      "an d e </w>  ->  3\n",
      "an d a </w>  ->  2\n",
      "an d a m o s </w>  ->  2\n",
      "an d a r i a </w>  ->  2\n",
      "an d a v a </w>  ->  2\n",
      "an d e m </w>  ->  2\n",
      "an d e m o s </w>  ->  2\n",
      "an d a i </w>  ->  1\n",
      "an d a i s </w>  ->  1\n",
      "an d a m </w>  ->  1\n",
      "an d a r a m </w>  ->  1\n",
      "an d a r e i </w>  ->  1\n",
      "an d a r e i s </w>  ->  1\n",
      "an d a r e m o s </w>  ->  1\n",
      "an d a r i a m </w>  ->  1\n",
      "... (mostrando apenas 15 entradas)\n",
      "\n",
      "=== PASSO 4.2: Contagem de pares (top 10) ===\n",
      "('an', 'd') -> 41\n",
      "('d', 'a') -> 27\n",
      "('s', '</w>') -> 18\n",
      "('a', 'r') -> 13\n",
      "('d', 'e') -> 10\n",
      "('a', 'm') -> 8\n",
      "('m', 'o') -> 7\n",
      "('o', 's') -> 7\n",
      "('a', '</w>') -> 6\n",
      "('m', '</w>') -> 6\n",
      "\n",
      "=== PASSO 5.2: Melhor par para merge ===\n",
      "Par escolhido: ('an', 'd') (freq=41)\n",
      "Novo símbolo: 'and'\n",
      "\n",
      "=== PASSO 6.2: Vocabulário após merge (amostra) ===\n",
      "and e </w>  ->  3\n",
      "and a </w>  ->  2\n",
      "and a m o s </w>  ->  2\n",
      "and a r i a </w>  ->  2\n",
      "and a v a </w>  ->  2\n",
      "and e m </w>  ->  2\n",
      "and e m o s </w>  ->  2\n",
      "and a i </w>  ->  1\n",
      "and a i s </w>  ->  1\n",
      "and a m </w>  ->  1\n",
      "and a r a m </w>  ->  1\n",
      "and a r e i </w>  ->  1\n",
      "and a r e i s </w>  ->  1\n",
      "and a r e m o s </w>  ->  1\n",
      "and a r i a m </w>  ->  1\n",
      "... (mostrando apenas 15 entradas)\n",
      "\n",
      "=== PASSO 4.3: Contagem de pares (top 10) ===\n",
      "('and', 'a') -> 27\n",
      "('s', '</w>') -> 18\n",
      "('a', 'r') -> 13\n",
      "('and', 'e') -> 10\n",
      "('a', 'm') -> 8\n",
      "('m', 'o') -> 7\n",
      "('o', 's') -> 7\n",
      "('a', '</w>') -> 6\n",
      "('m', '</w>') -> 6\n",
      "('e', 'i') -> 6\n",
      "\n",
      "=== PASSO 5.3: Melhor par para merge ===\n",
      "Par escolhido: ('and', 'a') (freq=27)\n",
      "Novo símbolo: 'anda'\n",
      "\n",
      "=== PASSO 6.3: Vocabulário após merge (amostra) ===\n",
      "and e </w>  ->  3\n",
      "and e m </w>  ->  2\n",
      "and e m o s </w>  ->  2\n",
      "anda </w>  ->  2\n",
      "anda m o s </w>  ->  2\n",
      "anda r i a </w>  ->  2\n",
      "anda v a </w>  ->  2\n",
      "and e i </w>  ->  1\n",
      "and e i s </w>  ->  1\n",
      "and e s </w>  ->  1\n",
      "and o </w>  ->  1\n",
      "and o u </w>  ->  1\n",
      "and á v a m o s </w>  ->  1\n",
      "and á v e i s </w>  ->  1\n",
      "anda i </w>  ->  1\n",
      "... (mostrando apenas 15 entradas)\n",
      "\n",
      "=== PASSO 4.4: Contagem de pares (top 10) ===\n",
      "('s', '</w>') -> 18\n",
      "('anda', 'r') -> 13\n",
      "('and', 'e') -> 10\n",
      "('m', 'o') -> 7\n",
      "('o', 's') -> 7\n",
      "('m', '</w>') -> 6\n",
      "('e', 'i') -> 6\n",
      "('i', 's') -> 5\n",
      "('a', 'm') -> 5\n",
      "('v', 'a') -> 5\n",
      "\n",
      "=== PASSO 5.4: Melhor par para merge ===\n",
      "Par escolhido: ('s', '</w>') (freq=18)\n",
      "Novo símbolo: 's</w>'\n",
      "\n",
      "=== PASSO 6.4: Vocabulário após merge (amostra) ===\n",
      "and e </w>  ->  3\n",
      "and e m </w>  ->  2\n",
      "and e m o s</w>  ->  2\n",
      "anda </w>  ->  2\n",
      "anda m o s</w>  ->  2\n",
      "anda r i a </w>  ->  2\n",
      "anda v a </w>  ->  2\n",
      "and e i </w>  ->  1\n",
      "and e i s</w>  ->  1\n",
      "and e s</w>  ->  1\n",
      "and o </w>  ->  1\n",
      "and o u </w>  ->  1\n",
      "and á v a m o s</w>  ->  1\n",
      "and á v e i s</w>  ->  1\n",
      "anda i </w>  ->  1\n",
      "... (mostrando apenas 15 entradas)\n",
      "\n",
      "=== PASSO 4.5: Contagem de pares (top 10) ===\n",
      "('anda', 'r') -> 13\n",
      "('and', 'e') -> 10\n",
      "('m', 'o') -> 7\n",
      "('o', 's</w>') -> 7\n",
      "('m', '</w>') -> 6\n",
      "('e', 'i') -> 6\n",
      "('i', 's</w>') -> 5\n",
      "('a', 'm') -> 5\n",
      "('v', 'a') -> 5\n",
      "('e', 'm') -> 5\n",
      "\n",
      "=== PASSO 5.5: Melhor par para merge ===\n",
      "Par escolhido: ('anda', 'r') (freq=13)\n",
      "Novo símbolo: 'andar'\n",
      "\n",
      "=== PASSO 6.5: Vocabulário após merge (amostra) ===\n",
      "and e </w>  ->  3\n",
      "and e m </w>  ->  2\n",
      "and e m o s</w>  ->  2\n",
      "anda </w>  ->  2\n",
      "anda m o s</w>  ->  2\n",
      "anda v a </w>  ->  2\n",
      "andar i a </w>  ->  2\n",
      "and e i </w>  ->  1\n",
      "and e i s</w>  ->  1\n",
      "and e s</w>  ->  1\n",
      "and o </w>  ->  1\n",
      "and o u </w>  ->  1\n",
      "and á v a m o s</w>  ->  1\n",
      "and á v e i s</w>  ->  1\n",
      "anda i </w>  ->  1\n",
      "... (mostrando apenas 15 entradas)\n",
      "\n",
      "=== PASSO 7: Tokens finais (vocabulário de subpalavras) ===\n",
      "['</w>', 'a', 'and', 'anda', 'andar', 'e', 'i', 'm', 'o', 's', 's</w>', 't', 'u', 'v', 'á', 'ã', 'í']\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'</w>': 0,\n",
       " 'a': 1,\n",
       " 'and': 2,\n",
       " 'anda': 3,\n",
       " 'andar': 4,\n",
       " 'e': 5,\n",
       " 'i': 6,\n",
       " 'm': 7,\n",
       " 'o': 8,\n",
       " 's': 9,\n",
       " 's</w>': 10,\n",
       " 't': 11,\n",
       " 'u': 12,\n",
       " 'v': 13,\n",
       " 'á': 14,\n",
       " 'ã': 15,\n",
       " 'í': 16}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [\n",
    "    # Presente do Indicativo\n",
    "    \"ando\",\n",
    "    \"andas\",\n",
    "    \"anda\",\n",
    "    \"andamos\",\n",
    "    \"andais\",\n",
    "    \"andam\",\n",
    "    # Pretérito Perfeito do Indicativo\n",
    "    \"andei\",\n",
    "    \"andaste\",\n",
    "    \"andou\",\n",
    "    \"andamos\",\n",
    "    \"andastes\",\n",
    "    \"andaram\",\n",
    "    # Pretérito Imperfeito do Indicativo\n",
    "    \"andava\",\n",
    "    \"andavas\",\n",
    "    \"andava\",\n",
    "    \"andávamos\",\n",
    "    \"andáveis\",\n",
    "    \"andavam\",\n",
    "    # Futuro do Presente do Indicativo\n",
    "    \"andarei\",\n",
    "    \"andarás\",\n",
    "    \"andará\",\n",
    "    \"andaremos\",\n",
    "    \"andareis\",\n",
    "    \"andarão\",\n",
    "    # Futuro do Pretérito (Condicional)\n",
    "    \"andaria\",\n",
    "    \"andarias\",\n",
    "    \"andaria\",\n",
    "    \"andaríamos\",\n",
    "    \"andaríeis\",\n",
    "    \"andariam\",\n",
    "    # Presente do Subjuntivo\n",
    "    \"ande\",\n",
    "    \"andes\",\n",
    "    \"ande\",\n",
    "    \"andemos\",\n",
    "    \"andeis\",\n",
    "    \"andem\",\n",
    "    # Imperativo Afirmativo\n",
    "    \"anda\",\n",
    "    \"ande\",\n",
    "    \"andemos\",\n",
    "    \"andai\",\n",
    "    \"andem\",\n",
    "]\n",
    "\n",
    "\n",
    "bpe = BytePairEncoderDecoder(end_of_word=\"</w>\")\n",
    "resultado = bpe.train(corpus=corpus, num_merges=5, verbose=True)\n",
    "resultado.token_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01bb8f4f-1f38-4ec8-87ad-b532c9f86ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(texto_novo)=10\n",
      "ids=[2, 8, 0, 3, 10], len(ids)=5\n"
     ]
    }
   ],
   "source": [
    "texto_novo = \"ando andas\"\n",
    "print(f\"{len(texto_novo)=}\")\n",
    "ids = bpe.encode(texto_novo, verbose=False)\n",
    "print(f\"{ids=}, {len(ids)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4410c11a-a148-4b5b-81b4-9a0a6724192c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxa_compressao = 1 - (len(ids) / len(texto_novo))\n",
    "taxa_compressao"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
